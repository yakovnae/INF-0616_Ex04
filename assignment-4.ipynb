{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF-616 - Tarefa 4 - TF-IDF, seleção de características e redução de dimensionalidade\n",
    "\n",
    "Professor: Jacques Wainer -- wainer@ic.unicamp.br  \n",
    "Monitor: Lucas David -- ra188972@students.ic.unicamp.br\n",
    "\n",
    "Instituto de Computação - Unicamp  \n",
    "2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(9510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algumas funções que podem ser úteis mais a frente:\n",
    "\n",
    "def describe(x, y, classes):\n",
    "    \"\"\"Descreve um conjunto de dados.\n",
    "    \n",
    "    :param x: np.ndarray, as amostras no conjunto.\n",
    "    :param y: np.ndarray, os rotulos associados as amostras `x`.\n",
    "    :param classes: list, uma lista com os nomes de cada classe. \n",
    "    \"\"\"\n",
    "    samples, features = (len(x), len(x[0])) if isinstance(x, list) else x.shape\n",
    "\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    print('  frequência das classes:',\n",
    "          *('    %s: %i' % e for e in zip(classes, counts)),\n",
    "          sep='\\n')\n",
    "\n",
    "def show_datasets(x, y, classes, title):\n",
    "    \"\"\"Encontra um \"embedding\" de um conjunto que alinha as direções\n",
    "       de maximiza separação das amostras com os eixos da base canônica,\n",
    "       permitindo uma melhor vizualização do conjunto.\n",
    "    \n",
    "    :param x: np.ndarray, as amostras do conjunto.\n",
    "    :param y: np.ndarray, os rotulos associados as amostras `x`.\n",
    "    :param title: str, o titulo do conjunto a ser exibido.\n",
    "    \"\"\"\n",
    "    x = TruncatedSVD(n_components=2).fit_transform(x)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for c in np.unique(y):\n",
    "        s = y == c\n",
    "        plt.scatter(x[s][:, 0], x[s][:, 1], label=classes[c])\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Matriz de Confusão',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    width = max(6, len(classes))\n",
    "    plt.figure(figsize=(width, width // 2))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Verdadeiro')\n",
    "    plt.xlabel('Predito')\n",
    "\n",
    "def train_and_report(grid, train, test, classes):\n",
    "    if not isinstance(grid, GridSearchCV):\n",
    "        raise ValueError('Você deve passar um objeto da classe `GridSearchCV` '\n",
    "                         'à função `train_and_report`. Ajuste seu modelo e sua '\n",
    "                         'chamada apropriadamente.')\n",
    "    grid.fit(*train)\n",
    "    print('Melhores parâmetros:', grid.best_params_)\n",
    "    print('Melhor pontuação sobre validação:', grid.best_score_)\n",
    "    \n",
    "    print('Resultados sobre a validação cruzada:')\n",
    "    properties = ['params',\n",
    "                  'mean_fit_time',\n",
    "                  'rank_test_score',\n",
    "                  'mean_test_score']\n",
    "    display(pd.DataFrame({p: grid.cv_results_[p] for p in properties})\n",
    "              .set_index('rank_test_score')\n",
    "              .sort_index())\n",
    "\n",
    "    print('Resultados sobre o teste:')\n",
    "    p = grid.predict(test[0])\n",
    "    print(metrics.classification_report(test[1], p))\n",
    "    plot_confusion_matrix(metrics.confusion_matrix(test[1], p), classes,\n",
    "                          normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução ao 20 News Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# O codigo abaixo ira baixar e carregar o conjunto `20newsgroups`.\n",
    "# Leia sobre este conjunto aqui: http://scikit-learn.org/stable/datasets/twenty_newsgroups.html\n",
    "\n",
    "train, test = (datasets.fetch_20newsgroups(subset=subset, shuffle=True)\n",
    "               for subset in ('train', 'test'))\n",
    "\n",
    "print('Algumas amostras em 20 News Groups:')\n",
    "samples_to_show = 10\n",
    "display(pd.DataFrame({'article': [a[320:370] for a in train.data[:samples_to_show]],\n",
    "                      'label': np.asarray(train.target_names)[train.target[:samples_to_show]]}))\n",
    "\n",
    "print('Conjunto 20 News Groups treino:')\n",
    "describe(train.data, train.target, train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vamos binarizar o problema:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.classes_ = train.target_names\n",
    "\n",
    "computing_classes, rec_classes = ([t for t in train.target_names if tag in t]\n",
    "                                   for tag in ('comp.', 'soc.religion.'))\n",
    "computing_codes, rec_codes = (le.transform(t)\n",
    "                              for t in (computing_classes, rec_classes))\n",
    "\n",
    "binary_set = []\n",
    "\n",
    "for (data, target) in ((train.data, train.target), (test.data, test.target)):\n",
    "    computing_samples = np.in1d(target, computing_codes)\n",
    "    rec_samples = np.in1d(target, rec_codes)\n",
    "    \n",
    "    x0 = [tx for tx, selected in zip(data, computing_samples) if selected]\n",
    "    x1 = [tx for tx, selected in zip(data, rec_samples) if selected]\n",
    "    \n",
    "    binary_set += [(x0 + x1, np.concatenate((np.zeros(len(x0)), np.ones(len(x1)))))]\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = binary_set\n",
    "target_names = ['computação', 'religião']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((y_train == 0).sum(), 'artigos relacionadas à computação')\n",
    "print((y_train == 1).sum(), 'artigos relacionados à religião')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processando texto com o TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Vetorize as amostras de texto em *20newgroups* em um conjunto de características utilizando o TF-IDF. Utilize as palavras de parada da lingua inglesa.**\n",
    "\n",
    "2. **Em seguida, remova todas as features que não possuam uma variância maior ou igual à $t = 1e^{-4}$.**\n",
    "\n",
    "3. **Finalmente, treine um classificador `LogisticRegression` buscando por valores de `C` no intervalo *(100, 10,000)***\n",
    "\n",
    "Dica: use o parâmetro `verbose=2` quando iniciar o grid-search. Isso lhe dará uma ideia do progresso da busca, caso ela tome muito tempo.\n",
    "\n",
    "Bônus: tente executar todas ações de uma única vez, utilizando a classe `Pipeline`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn... import ...\n",
    "# params = {...}\n",
    "# model = ...\n",
    "# grid = ...\n",
    "\n",
    "train_and_report(grid,\n",
    "                 train=(x_train, y_train),\n",
    "                 test=(x_test, y_test),\n",
    "                 classes=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reporte a ROC AUC sobre o conjunto de teste.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = ...\n",
    "# print('ROC:', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando o conjunto após a transformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resgata o modelo com os parâmetros de melhor pontuação sobre as\n",
    "# dobras de validação, retreinado sobre todo o conjunto de treino.\n",
    "model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Você usou o pipeline no passo anterior?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_used = True  # altere aqui se necessário\n",
    "\n",
    "if pipeline_used:\n",
    "    transformers = model.steps[:2]\n",
    "else:\n",
    "    tfidf = None # substitua por seu transformador TF-IDF.\n",
    "    vt = None # substitua por seu seletor de features baseado em variância.\n",
    "    transformers = [\n",
    "        ('tfidfvectorizer', tfidf),\n",
    "        ('variancethreshold', vt),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Cria um novo pipeline com o TF-IDF e o seletor de características.\n",
    "transformer = Pipeline(transformers)\n",
    "t_train = transformer.transform(x_train)\n",
    "\n",
    "print('Número de características após transformação TF-IDF:',\n",
    "      transformer.named_steps['tfidfvectorizer'].transform(x_train).shape[1])\n",
    "print('Número de características após seleção de características:', t_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Estatísticas sobre a variância das características antes e após a seleção:')\n",
    "\n",
    "vt = transformer.named_steps['variancethreshold']\n",
    "chosen_features = vt.get_support()\n",
    "\n",
    "var_stats = pd.concat((pd.Series(vt.variances_).describe(),\n",
    "                       pd.Series(vt.variances_[chosen_features]).describe()),\n",
    "                      axis=1)\n",
    "var_stats.columns = ['original', 'selected']\n",
    "display(var_stats.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exibindo um *embedding* para o conjunto:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_datasets(t_train, y_train.astype(int),\n",
    "              target_names,\n",
    "              title='20 News Groups/train (comp,rec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redução de dimensionalidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Utilize o `Non-Negative Matrix Factorization (NMF)` para reduzir a dimensionalidade do conjunto 20 news groups binarizado e vetorizado (mas não reduzido com a seleção de características) acima.**\n",
    "2. **Utilize um classificador baseado no algoritmo Random Forest, buscando pelo número de árvores no intervalo *(100, 500)*.**\n",
    "\n",
    "Dica: use um `GridSearchCV#n_jobs` pequeno aqui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = ...\n",
    "# model = ...\n",
    "# grid = ...\n",
    "train_and_report(grid,\n",
    "                 train=(z_train, y_train),\n",
    "                 test=(z_test, y_test),\n",
    "                 classes=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reporte a ROC AUC sobre o conjunto de teste:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('ROC AUC:', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qual dos dois conjuntos de algoritmos apresentou o melhor resultado?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verifique se combater o desbalanceamento das classes em treino ao ponderar as amostras pelo inverso das frequências de suas classes (utilizando o parâmetro `class_weight='balanced'`) melhora os resultados:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# params = ...\n",
    "# model = ...\n",
    "# grid = ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
