{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF-616 - Tarefa 4 - TF-IDF, seleção de características e redução de dimensionalidade\n",
    "\n",
    "Professor: Jacques Wainer -- wainer@ic.unicamp.br  \n",
    "Monitor: Lucas David -- ra188972@students.ic.unicamp.br\n",
    "\n",
    "Alunos: Carlos Eduardo Fernandes e Yakov Nae\n",
    "        \n",
    "Instituto de Computação - Unicamp  \n",
    "2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(9510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algumas funções que podem ser úteis mais a frente:\n",
    "\n",
    "def describe(x, y, classes):\n",
    "    \"\"\"Descreve um conjunto de dados.\n",
    "    \n",
    "    :param x: np.ndarray, as amostras no conjunto.\n",
    "    :param y: np.ndarray, os rotulos associados as amostras `x`.\n",
    "    :param classes: list, uma lista com os nomes de cada classe. \n",
    "    \"\"\"\n",
    "    samples, features = (len(x), len(x[0])) if isinstance(x, list) else x.shape\n",
    "\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    print('  frequência das classes:',\n",
    "          *('    %s: %i' % e for e in zip(classes, counts)),\n",
    "          sep='\\n')\n",
    "\n",
    "def show_datasets(x, y, classes, title):\n",
    "    \"\"\"Encontra um \"embedding\" de um conjunto que alinha as direções\n",
    "       de maximiza separação das amostras com os eixos da base canônica,\n",
    "       permitindo uma melhor vizualização do conjunto.\n",
    "    \n",
    "    :param x: np.ndarray, as amostras do conjunto.\n",
    "    :param y: np.ndarray, os rotulos associados as amostras `x`.\n",
    "    :param title: str, o titulo do conjunto a ser exibido.\n",
    "    \"\"\"\n",
    "    x = TruncatedSVD(n_components=2).fit_transform(x)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for c in np.unique(y):\n",
    "        s = y == c\n",
    "        plt.scatter(x[s][:, 0], x[s][:, 1], label=classes[c])\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Matriz de Confusão',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    width = max(6, len(classes))\n",
    "    plt.figure(figsize=(width, width // 2))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Verdadeiro')\n",
    "    plt.xlabel('Predito')\n",
    "\n",
    "def train_and_report(grid, train, test, classes):\n",
    "    if not isinstance(grid, GridSearchCV):\n",
    "        raise ValueError('Você deve passar um objeto da classe `GridSearchCV` '\n",
    "                         'à função `train_and_report`. Ajuste seu modelo e sua '\n",
    "                         'chamada apropriadamente.')\n",
    "    grid.fit(*train)\n",
    "    print('Melhores parâmetros:', grid.best_params_)\n",
    "    print('Melhor pontuação sobre validação:', grid.best_score_)\n",
    "    \n",
    "    print('Resultados sobre a validação cruzada:')\n",
    "    properties = ['params',\n",
    "                  'mean_fit_time',\n",
    "                  'rank_test_score',\n",
    "                  'mean_test_score']\n",
    "    display(pd.DataFrame({p: grid.cv_results_[p] for p in properties})\n",
    "              .set_index('rank_test_score')\n",
    "              .sort_index())\n",
    "\n",
    "    print('Resultados sobre o teste:')\n",
    "    p = grid.predict(test[0])\n",
    "    print(metrics.classification_report(test[1], p))\n",
    "    plot_confusion_matrix(metrics.confusion_matrix(test[1], p), classes,\n",
    "                          normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução ao 20 News Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algumas amostras em 20 News Groups:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arly 70s. It was called a Bricklin. The doors were</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who upgraded their SI clock oscillator have\\nshare</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bit sooner than i intended to be...\\n\\ni'm looking</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ass1.iastate.edu&gt;:\\n&gt; &gt; Anyone know about the Weite</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acs1.ttu.edu (Pack Rat) writes...\\n&gt;&gt;&gt;\"Clear cautio</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>article &lt;1qv87v$4j3@transfer.stratus.com&gt; cdt@sw.</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>because of mail-bouncing probs (Sean, Debra, and</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>93:29 \"Although SCSI is twice as fasst as ESDI,\\n&gt;&gt;</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>that it is a\\n&gt;\\thardware compression board that wo</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                article  \\\n",
       "0  arly 70s. It was called a Bricklin. The doors were     \n",
       "1   who upgraded their SI clock oscillator have\\nshare    \n",
       "2   bit sooner than i intended to be...\\n\\ni'm looking    \n",
       "3  ass1.iastate.edu>:\\n> > Anyone know about the Weite    \n",
       "4  acs1.ttu.edu (Pack Rat) writes...\\n>>>\"Clear cautio    \n",
       "5   article <1qv87v$4j3@transfer.stratus.com> cdt@sw.     \n",
       "6   because of mail-bouncing probs (Sean, Debra, and      \n",
       "7  93:29 \"Although SCSI is twice as fasst as ESDI,\\n>>    \n",
       "8                                                         \n",
       "9   that it is a\\n>\\thardware compression board that wo   \n",
       "\n",
       "                      label  \n",
       "0  rec.autos                 \n",
       "1  comp.sys.mac.hardware     \n",
       "2  comp.sys.mac.hardware     \n",
       "3  comp.graphics             \n",
       "4  sci.space                 \n",
       "5  talk.politics.guns        \n",
       "6  sci.med                   \n",
       "7  comp.sys.ibm.pc.hardware  \n",
       "8  comp.os.ms-windows.misc   \n",
       "9  comp.sys.mac.hardware     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto 20 News Groups treino:\n",
      "  frequência das classes:\n",
      "    alt.atheism: 480\n",
      "    comp.graphics: 584\n",
      "    comp.os.ms-windows.misc: 591\n",
      "    comp.sys.ibm.pc.hardware: 590\n",
      "    comp.sys.mac.hardware: 578\n",
      "    comp.windows.x: 593\n",
      "    misc.forsale: 585\n",
      "    rec.autos: 594\n",
      "    rec.motorcycles: 598\n",
      "    rec.sport.baseball: 597\n",
      "    rec.sport.hockey: 600\n",
      "    sci.crypt: 595\n",
      "    sci.electronics: 591\n",
      "    sci.med: 594\n",
      "    sci.space: 593\n",
      "    soc.religion.christian: 599\n",
      "    talk.politics.guns: 546\n",
      "    talk.politics.mideast: 564\n",
      "    talk.politics.misc: 465\n",
      "    talk.religion.misc: 377\n"
     ]
    }
   ],
   "source": [
    "# O codigo abaixo ira baixar e carregar o conjunto `20newsgroups`.\n",
    "# Leia sobre este conjunto aqui: http://scikit-learn.org/stable/datasets/twenty_newsgroups.html\n",
    "\n",
    "train, test = (datasets.fetch_20newsgroups(subset=subset, shuffle=True)\n",
    "               for subset in ('train', 'test'))\n",
    "\n",
    "print('Algumas amostras em 20 News Groups:')\n",
    "samples_to_show = 10\n",
    "display(pd.DataFrame({'article': [a[320:370] for a in train.data[:samples_to_show]],\n",
    "                      'label': np.asarray(train.target_names)[train.target[:samples_to_show]]}))\n",
    "\n",
    "print('Conjunto 20 News Groups treino:')\n",
    "describe(train.data, train.target, train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vamos binarizar o problema:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.classes_ = train.target_names\n",
    "\n",
    "computing_classes, rec_classes = ([t for t in train.target_names if tag in t]\n",
    "                                   for tag in ('comp.', 'soc.religion.'))\n",
    "computing_codes, rec_codes = (le.transform(t)\n",
    "                              for t in (computing_classes, rec_classes))\n",
    "\n",
    "binary_set = []\n",
    "\n",
    "for (data, target) in ((train.data, train.target), (test.data, test.target)):\n",
    "    computing_samples = np.in1d(target, computing_codes)\n",
    "    rec_samples = np.in1d(target, rec_codes)\n",
    "    \n",
    "    x0 = [tx for tx, selected in zip(data, computing_samples) if selected]\n",
    "    x1 = [tx for tx, selected in zip(data, rec_samples) if selected]\n",
    "    \n",
    "    binary_set += [(x0 + x1, np.concatenate((np.zeros(len(x0)), np.ones(len(x1)))))]\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = binary_set\n",
    "target_names = ['computação', 'religião']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2936 artigos relacionadas à computação\n",
      "599 artigos relacionados à religião\n"
     ]
    }
   ],
   "source": [
    "print((y_train == 0).sum(), 'artigos relacionadas à computação')\n",
    "print((y_train == 1).sum(), 'artigos relacionados à religião')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processando texto com o TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Vetorize as amostras de texto em *20newgroups* em um conjunto de características utilizando o TF-IDF. Utilize as palavras de parada da lingua inglesa.**\n",
    "\n",
    "2. **Em seguida, remova todas as features que não possuam uma variância maior ou igual à $t = 1e^{-4}$.**\n",
    "\n",
    "3. **Finalmente, treine um classificador `LogisticRegression` buscando por valores de `C` no intervalo *(100, 10,000)***\n",
    "\n",
    "Dica: use o parâmetro `verbose=2` quando iniciar o grid-search. Isso lhe dará uma ideia do progresso da busca, caso ela tome muito tempo.\n",
    "\n",
    "Bônus: tente executar todas ações de uma única vez, utilizando a classe `Pipeline`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Parameter values for parameter (var_filter__threshold) need to be a sequence(but not a string) or np.ndarray.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6bac0c369fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m'clf__C'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m }\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m# params = {...}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# model = ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, estimator, param_grid, scoring, fit_params, n_jobs, iid, refit, cv, verbose, pre_dispatch, error_score, return_train_score)\u001b[0m\n\u001b[1;32m   1075\u001b[0m             return_train_score=return_train_score)\n\u001b[1;32m   1076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1077\u001b[0;31m         \u001b[0m_check_param_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_param_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_check_param_grid\u001b[0;34m(param_grid)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 raise ValueError(\"Parameter values for parameter ({0}) need \"\n\u001b[1;32m    355\u001b[0m                                  \u001b[0;34m\"to be a sequence(but not a string) or\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                                  \" np.ndarray.\".format(name))\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Parameter values for parameter (var_filter__threshold) need to be a sequence(but not a string) or np.ndarray."
     ]
    }
   ],
   "source": [
    "# from sklearn... import ...\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "   \n",
    "my_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('var_filter', VarianceThreshold(threshold=1/1000)),\n",
    "    ('clf', LogisticRegression(C=1e5))\n",
    "])\n",
    "parameters = {\n",
    "    'var_filter__threshold': (1/1000),\n",
    "    'clf__C': (100, 10000),\n",
    "}\n",
    "grid = GridSearchCV(my_pipeline, parameters, verbose=2)\n",
    "# params = {...}\n",
    "# model = ...\n",
    "# grid = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9834ec5a8815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_and_report(grid,\n\u001b[0m\u001b[1;32m      2\u001b[0m                  \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  classes=target_names)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid' is not defined"
     ]
    }
   ],
   "source": [
    "train_and_report(grid,\n",
    "                 train=(x_train, y_train),\n",
    "                 test=(x_test, y_test),\n",
    "                 classes=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reporte a ROC AUC sobre o conjunto de teste.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = ...\n",
    "# print('ROC:', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando o conjunto após a transformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resgata o modelo com os parâmetros de melhor pontuação sobre as\n",
    "# dobras de validação, retreinado sobre todo o conjunto de treino.\n",
    "model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Você usou o pipeline no passo anterior?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_used = True  # altere aqui se necessário\n",
    "\n",
    "if pipeline_used:\n",
    "    transformers = model.steps[:2]\n",
    "else:\n",
    "    tfidf = None # substitua por seu transformador TF-IDF.\n",
    "    vt = None # substitua por seu seletor de features baseado em variância.\n",
    "    transformers = [\n",
    "        ('tfidfvectorizer', tfidf),\n",
    "        ('variancethreshold', vt),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Cria um novo pipeline com o TF-IDF e o seletor de características.\n",
    "transformer = Pipeline(transformers)\n",
    "t_train = transformer.transform(x_train)\n",
    "\n",
    "print('Número de características após transformação TF-IDF:',\n",
    "      transformer.named_steps['tfidfvectorizer'].transform(x_train).shape[1])\n",
    "print('Número de características após seleção de características:', t_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Estatísticas sobre a variância das características antes e após a seleção:')\n",
    "\n",
    "vt = transformer.named_steps['variancethreshold']\n",
    "chosen_features = vt.get_support()\n",
    "\n",
    "var_stats = pd.concat((pd.Series(vt.variances_).describe(),\n",
    "                       pd.Series(vt.variances_[chosen_features]).describe()),\n",
    "                      axis=1)\n",
    "var_stats.columns = ['original', 'selected']\n",
    "display(var_stats.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exibindo um *embedding* para o conjunto:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_datasets(t_train, y_train.astype(int),\n",
    "              target_names,\n",
    "              title='20 News Groups/train (comp,rec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redução de dimensionalidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Utilize o `Non-Negative Matrix Factorization (NMF)` para reduzir a dimensionalidade do conjunto 20 news groups binarizado e vetorizado (mas não reduzido com a seleção de características) acima.**\n",
    "2. **Utilize um classificador baseado no algoritmo Random Forest, buscando pelo número de árvores no intervalo *(100, 500)*.**\n",
    "\n",
    "Dica: use um `GridSearchCV#n_jobs` pequeno aqui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = ...\n",
    "# model = ...\n",
    "# grid = ...\n",
    "train_and_report(grid,\n",
    "                 train=(z_train, y_train),\n",
    "                 test=(z_test, y_test),\n",
    "                 classes=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reporte a ROC AUC sobre o conjunto de teste:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('ROC AUC:', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qual dos dois conjuntos de algoritmos apresentou o melhor resultado?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verifique se combater o desbalanceamento das classes em treino ao ponderar as amostras pelo inverso das frequências de suas classes (utilizando o parâmetro `class_weight='balanced'`) melhora os resultados:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# params = ...\n",
    "# model = ...\n",
    "# grid = ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
