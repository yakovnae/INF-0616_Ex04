{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF-616 - Tarefa 4 - TF-IDF, seleção de características e redução de dimensionalidade\n",
    "\n",
    "Professor: Jacques Wainer -- wainer@ic.unicamp.br  \n",
    "Monitor: Lucas David -- ra188972@students.ic.unicamp.br\n",
    "\n",
    "Alunos: Carlos Eduardo Fernandes e Yakov Nae\n",
    "        \n",
    "Instituto de Computação - Unicamp  \n",
    "2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(9510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algumas funções que podem ser úteis mais a frente:\n",
    "\n",
    "def describe(x, y, classes):\n",
    "    \"\"\"Descreve um conjunto de dados.\n",
    "    \n",
    "    :param x: np.ndarray, as amostras no conjunto.\n",
    "    :param y: np.ndarray, os rotulos associados as amostras `x`.\n",
    "    :param classes: list, uma lista com os nomes de cada classe. \n",
    "    \"\"\"\n",
    "    samples, features = (len(x), len(x[0])) if isinstance(x, list) else x.shape\n",
    "\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    print('  frequência das classes:',\n",
    "          *('    %s: %i' % e for e in zip(classes, counts)),\n",
    "          sep='\\n')\n",
    "\n",
    "def show_datasets(x, y, classes, title):\n",
    "    \"\"\"Encontra um \"embedding\" de um conjunto que alinha as direções\n",
    "       de maximiza separação das amostras com os eixos da base canônica,\n",
    "       permitindo uma melhor vizualização do conjunto.\n",
    "    \n",
    "    :param x: np.ndarray, as amostras do conjunto.\n",
    "    :param y: np.ndarray, os rotulos associados as amostras `x`.\n",
    "    :param title: str, o titulo do conjunto a ser exibido.\n",
    "    \"\"\"\n",
    "    x = TruncatedSVD(n_components=2).fit_transform(x)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for c in np.unique(y):\n",
    "        s = y == c\n",
    "        plt.scatter(x[s][:, 0], x[s][:, 1], label=classes[c])\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Matriz de Confusão',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    width = max(6, len(classes))\n",
    "    plt.figure(figsize=(width, width // 2))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Verdadeiro')\n",
    "    plt.xlabel('Predito')\n",
    "\n",
    "def train_and_report(grid, train, test, classes):\n",
    "    if not isinstance(grid, GridSearchCV):\n",
    "        raise ValueError('Você deve passar um objeto da classe `GridSearchCV` '\n",
    "                         'à função `train_and_report`. Ajuste seu modelo e sua '\n",
    "                         'chamada apropriadamente.')\n",
    "    grid.fit(*train)\n",
    "    print('Melhores parâmetros:', grid.best_params_)\n",
    "    print('Melhor pontuação sobre validação:', grid.best_score_)\n",
    "    \n",
    "    print('Resultados sobre a validação cruzada:')\n",
    "    properties = ['params',\n",
    "                  'mean_fit_time',\n",
    "                  'rank_test_score',\n",
    "                  'mean_test_score']\n",
    "    display(pd.DataFrame({p: grid.cv_results_[p] for p in properties})\n",
    "              .set_index('rank_test_score')\n",
    "              .sort_index())\n",
    "\n",
    "    print('Resultados sobre o teste:')\n",
    "    p = grid.predict(test[0])\n",
    "    print(metrics.classification_report(test[1], p))\n",
    "    plot_confusion_matrix(metrics.confusion_matrix(test[1], p), classes,\n",
    "                          normalize=True)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução ao 20 News Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algumas amostras em 20 News Groups:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ellme a model name, engine specs, years\\nof product</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 and 1.4 m floppies are especially requested.\\n\\nI</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>does anybody know any dirt on when the next round</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the code\\nand possibly introduce new bugs, they ju</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>irst point evidently was to show that not all weap</td>\n",
       "      <td>talk.politics.guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g to delete a file last September. \"Hmmm... 'News?</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASE in SPEED, the Mac Quadra uses this version of</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>blems with file icons being lost, but it's\\nhard to</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                article  \\\n",
       "0  ellme a model name, engine specs, years\\nof product    \n",
       "1  0 and 1.4 m floppies are especially requested.\\n\\nI    \n",
       "2   does anybody know any dirt on when the next round     \n",
       "3                                                         \n",
       "4   the code\\nand possibly introduce new bugs, they ju    \n",
       "5  irst point evidently was to show that not all weap     \n",
       "6  g to delete a file last September. \"Hmmm... 'News?     \n",
       "7  ASE in SPEED, the Mac Quadra uses this version of      \n",
       "8                                                         \n",
       "9  blems with file icons being lost, but it's\\nhard to    \n",
       "\n",
       "                      label  \n",
       "0  rec.autos                 \n",
       "1  comp.sys.mac.hardware     \n",
       "2  comp.sys.mac.hardware     \n",
       "3  comp.graphics             \n",
       "4  sci.space                 \n",
       "5  talk.politics.guns        \n",
       "6  sci.med                   \n",
       "7  comp.sys.ibm.pc.hardware  \n",
       "8  comp.os.ms-windows.misc   \n",
       "9  comp.sys.mac.hardware     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto 20 News Groups treino:\n",
      "  frequência das classes:\n",
      "    alt.atheism: 480\n",
      "    comp.graphics: 584\n",
      "    comp.os.ms-windows.misc: 591\n",
      "    comp.sys.ibm.pc.hardware: 590\n",
      "    comp.sys.mac.hardware: 578\n",
      "    comp.windows.x: 593\n",
      "    misc.forsale: 585\n",
      "    rec.autos: 594\n",
      "    rec.motorcycles: 598\n",
      "    rec.sport.baseball: 597\n",
      "    rec.sport.hockey: 600\n",
      "    sci.crypt: 595\n",
      "    sci.electronics: 591\n",
      "    sci.med: 594\n",
      "    sci.space: 593\n",
      "    soc.religion.christian: 599\n",
      "    talk.politics.guns: 546\n",
      "    talk.politics.mideast: 564\n",
      "    talk.politics.misc: 465\n",
      "    talk.religion.misc: 377\n"
     ]
    }
   ],
   "source": [
    "# O codigo abaixo ira baixar e carregar o conjunto `20newsgroups`.\n",
    "# Leia sobre este conjunto aqui: http://scikit-learn.org/stable/datasets/twenty_newsgroups.html\n",
    "\n",
    "train, test = (datasets.fetch_20newsgroups(subset=subset, remove=('headers', 'footers', 'quotes'), shuffle=True)\n",
    "               for subset in ('train', 'test'))\n",
    "\n",
    "print('Algumas amostras em 20 News Groups:')\n",
    "samples_to_show = 10\n",
    "display(pd.DataFrame({'article': [a[320:370] for a in train.data[:samples_to_show]],\n",
    "                      'label': np.asarray(train.target_names)[train.target[:samples_to_show]]}))\n",
    "\n",
    "print('Conjunto 20 News Groups treino:')\n",
    "describe(train.data, train.target, train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vamos binarizar o problema:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.classes_ = train.target_names\n",
    "\n",
    "computing_classes, rec_classes = ([t for t in train.target_names if tag in t]\n",
    "                                   for tag in ('comp.', 'soc.religion.'))\n",
    "computing_codes, rec_codes = (le.transform(t)\n",
    "                              for t in (computing_classes, rec_classes))\n",
    "\n",
    "binary_set = []\n",
    "\n",
    "for (data, target) in ((train.data, train.target), (test.data, test.target)):\n",
    "    computing_samples = np.in1d(target, computing_codes)\n",
    "    rec_samples = np.in1d(target, rec_codes)\n",
    "    \n",
    "    x0 = [tx for tx, selected in zip(data, computing_samples) if selected]\n",
    "    x1 = [tx for tx, selected in zip(data, rec_samples) if selected]\n",
    "    \n",
    "    binary_set += [(x0 + x1, np.concatenate((np.zeros(len(x0)), np.ones(len(x1)))))]\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = binary_set\n",
    "target_names = ['computação', 'religião']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2936 artigos relacionadas à computação\n",
      "599 artigos relacionados à religião\n"
     ]
    }
   ],
   "source": [
    "print((y_train == 0).sum(), 'artigos relacionadas à computação')\n",
    "print((y_train == 1).sum(), 'artigos relacionados à religião')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processando texto com o TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Vetorize as amostras de texto em *20newgroups* em um conjunto de características utilizando o TF-IDF. Utilize as palavras de parada da lingua inglesa.**\n",
    "\n",
    "2. **Em seguida, remova todas as features que não possuam uma variância maior ou igual à $t = 1e^{-4}$.**\n",
    "\n",
    "3. **Finalmente, treine um classificador `LogisticRegression` buscando por valores de `C` no intervalo *(100, 10,000)***\n",
    "\n",
    "Dica: use o parâmetro `verbose=2` quando iniciar o grid-search. Isso lhe dará uma ideia do progresso da busca, caso ela tome muito tempo.\n",
    "\n",
    "Bônus: tente executar todas ações de uma única vez, utilizando a classe `Pipeline`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] clf__C=100.0, var_filter__threshold=0.0001 ......................\n",
      "[CV] clf__C=100.0, var_filter__threshold=0.0001 ......................\n",
      "[CV] clf__C=100.0, var_filter__threshold=0.0001 ......................\n",
      "[CV] ....... clf__C=100.0, var_filter__threshold=0.0001, total=   1.7s\n",
      "[CV] ....... clf__C=100.0, var_filter__threshold=0.0001, total=   1.7s\n",
      "[CV] clf__C=166.81005372000593, var_filter__threshold=0.0001 .........\n",
      "[CV] ....... clf__C=100.0, var_filter__threshold=0.0001, total=   1.6s\n",
      "[CV] clf__C=166.81005372000593, var_filter__threshold=0.0001 .........\n",
      "[CV] clf__C=166.81005372000593, var_filter__threshold=0.0001 .........\n",
      "[CV]  clf__C=166.81005372000593, var_filter__threshold=0.0001, total=   1.4s\n",
      "[CV] clf__C=278.2559402207126, var_filter__threshold=0.0001 ..........\n",
      "[CV]  clf__C=166.81005372000593, var_filter__threshold=0.0001, total=   1.4s\n",
      "[CV] clf__C=278.2559402207126, var_filter__threshold=0.0001 ..........\n",
      "[CV]  clf__C=166.81005372000593, var_filter__threshold=0.0001, total=   1.5s\n",
      "[CV] clf__C=278.2559402207126, var_filter__threshold=0.0001 ..........\n",
      "[CV]  clf__C=278.2559402207126, var_filter__threshold=0.0001, total=   1.6s\n",
      "[CV]  clf__C=278.2559402207126, var_filter__threshold=0.0001, total=   1.6s\n",
      "[CV] clf__C=464.15888336127773, var_filter__threshold=0.0001 .........\n",
      "[CV] clf__C=464.15888336127773, var_filter__threshold=0.0001 .........\n",
      "[CV]  clf__C=278.2559402207126, var_filter__threshold=0.0001, total=   1.7s\n",
      "[CV] clf__C=464.15888336127773, var_filter__threshold=0.0001 .........\n",
      "[CV]  clf__C=464.15888336127773, var_filter__threshold=0.0001, total=   1.8s\n",
      "[CV]  clf__C=464.15888336127773, var_filter__threshold=0.0001, total=   1.8s\n",
      "[CV] clf__C=774.263682681127, var_filter__threshold=0.0001 ...........\n",
      "[CV] clf__C=774.263682681127, var_filter__threshold=0.0001 ...........\n",
      "[CV]  clf__C=464.15888336127773, var_filter__threshold=0.0001, total=   1.7s\n",
      "[CV] clf__C=774.263682681127, var_filter__threshold=0.0001 ...........\n",
      "[CV]  clf__C=774.263682681127, var_filter__threshold=0.0001, total=   1.3s\n",
      "[CV] clf__C=1291.549665014884, var_filter__threshold=0.0001 ..........\n",
      "[CV]  clf__C=774.263682681127, var_filter__threshold=0.0001, total=   1.3s\n",
      "[CV] clf__C=1291.549665014884, var_filter__threshold=0.0001 ..........\n",
      "[CV]  clf__C=774.263682681127, var_filter__threshold=0.0001, total=   1.2s\n",
      "[CV] clf__C=1291.549665014884, var_filter__threshold=0.0001 ..........\n",
      "[CV]  clf__C=1291.549665014884, var_filter__threshold=0.0001, total=   1.2s\n",
      "[CV]  clf__C=1291.549665014884, var_filter__threshold=0.0001, total=   1.3s\n",
      "[CV] clf__C=2154.4346900318824, var_filter__threshold=0.0001 .........\n",
      "[CV] clf__C=2154.4346900318824, var_filter__threshold=0.0001 .........\n",
      "[CV]  clf__C=1291.549665014884, var_filter__threshold=0.0001, total=   1.2s\n",
      "[CV] clf__C=2154.4346900318824, var_filter__threshold=0.0001 .........\n",
      "[CV]  clf__C=2154.4346900318824, var_filter__threshold=0.0001, total=   1.3s\n",
      "[CV] clf__C=3593.813663804626, var_filter__threshold=0.0001 ..........\n",
      "[CV]  clf__C=2154.4346900318824, var_filter__threshold=0.0001, total=   1.3s\n",
      "[CV] clf__C=3593.813663804626, var_filter__threshold=0.0001 ..........\n",
      "[CV]  clf__C=2154.4346900318824, var_filter__threshold=0.0001, total=   1.3s\n",
      "[CV] clf__C=3593.813663804626, var_filter__threshold=0.0001 ..........\n",
      "[CV]  clf__C=3593.813663804626, var_filter__threshold=0.0001, total=   1.4s\n",
      "[CV] clf__C=5994.8425031894085, var_filter__threshold=0.0001 .........\n",
      "[CV]  clf__C=3593.813663804626, var_filter__threshold=0.0001, total=   1.4s\n",
      "[CV] clf__C=5994.8425031894085, var_filter__threshold=0.0001 .........\n",
      "[CV]  clf__C=3593.813663804626, var_filter__threshold=0.0001, total=   1.3s\n",
      "[CV] clf__C=5994.8425031894085, var_filter__threshold=0.0001 .........\n",
      "[CV]  clf__C=5994.8425031894085, var_filter__threshold=0.0001, total=   1.3s\n",
      "[CV]  clf__C=5994.8425031894085, var_filter__threshold=0.0001, total=   1.3s\n",
      "[CV] clf__C=10000.0, var_filter__threshold=0.0001 ....................\n",
      "[CV] clf__C=10000.0, var_filter__threshold=0.0001 ....................\n",
      "[CV]  clf__C=5994.8425031894085, var_filter__threshold=0.0001, total=   1.3s\n",
      "[CV] clf__C=10000.0, var_filter__threshold=0.0001 ....................\n"
     ]
    }
   ],
   "source": [
    "# from sklearn... import ...\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "   \n",
    "my_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer( stop_words='english' )),\n",
    "    ('var_filter', VarianceThreshold()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "params = {\n",
    "    'var_filter__threshold': [1/10000],\n",
    "    'clf__C': np.logspace(2, 4, 10), #10 numbers from 10^2 to 10^4\n",
    "}\n",
    "grid = GridSearchCV(my_pipeline, params, n_jobs=3, verbose=2)\n",
    "# params = {...}\n",
    "# model = ...\n",
    "# grid = ...\n",
    "p_LR=train_and_report(grid,\n",
    "                 train=(x_train, y_train),\n",
    "                 test=(x_test, y_test),\n",
    "                 classes=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reporte a ROC AUC sobre o conjunto de teste.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('ROC AUC:', ...)\n",
    "roc_LR = metrics.roc_auc_score(p_LR, y_test)\n",
    "print('ROC:', roc_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando o conjunto após a transformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resgata o modelo com os parâmetros de melhor pontuação sobre as\n",
    "# dobras de validação, retreinado sobre todo o conjunto de treino.\n",
    "model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Você usou o pipeline no passo anterior?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_used = True  # altere aqui se necessário\n",
    "\n",
    "if pipeline_used:\n",
    "    transformers = model.steps[:2]\n",
    "else:\n",
    "    tfidf = None # substitua por seu transformador TF-IDF.\n",
    "    vt = None # substitua por seu seletor de features baseado em variância.\n",
    "    transformers = [\n",
    "        ('tfidfvectorizer', tfidf),\n",
    "        ('variancethreshold', vt),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Cria um novo pipeline com o TF-IDF e o seletor de características.\n",
    "transformer = Pipeline(transformers)\n",
    "t_train = transformer.transform(x_train)\n",
    "\n",
    "print('Número de características após transformação TF-IDF:',\n",
    "transformer.named_steps['tfidf'].transform(x_train).shape[1])\n",
    "print('Número de características após seleção de características:', t_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Estatísticas sobre a variância das características antes e após a seleção:')\n",
    "\n",
    "vt = transformer.named_steps['var_filter']\n",
    "chosen_features = vt.get_support()\n",
    "\n",
    "var_stats = pd.concat((pd.Series(vt.variances_).describe(),\n",
    "                       pd.Series(vt.variances_[chosen_features]).describe()),\n",
    "                      axis=1)\n",
    "var_stats.columns = ['original', 'selected']\n",
    "display(var_stats.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exibindo um *embedding* para o conjunto:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_datasets(t_train, y_train.astype(int),\n",
    "              target_names,\n",
    "              title='20 News Groups/train (comp,rec)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redução de dimensionalidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Utilize o `Non-Negative Matrix Factorization (NMF)` para reduzir a dimensionalidade do conjunto 20 news groups binarizado e vetorizado (mas não reduzido com a seleção de características) acima.**\n",
    "2. **Utilize um classificador baseado no algoritmo Random Forest, buscando pelo número de árvores no intervalo *(100, 500)*.**\n",
    "\n",
    "Dica: use um `GridSearchCV#n_jobs` pequeno aqui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "my_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer( stop_words='english' )),\n",
    "    ('nmf', NMF(n_components=20, init='random', random_state=0)),\n",
    "    ('clf', RandomForestClassifier(min_samples_split=3))\n",
    "])\n",
    "params = {\n",
    "    'clf__n_estimators': [100,200,300,400,500]\n",
    "}\n",
    "grid = GridSearchCV(my_pipeline, params, n_jobs=1, verbose=2)\n",
    "\n",
    "# params = ...\n",
    "# model = ...\n",
    "# grid = ...\n",
    "p_RF=train_and_report(grid,\n",
    "                 train=(x_train, y_train),\n",
    "                 test=(x_test, y_test),\n",
    "                 classes=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reporte a ROC AUC sobre o conjunto de teste:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('ROC AUC:', ...)\n",
    "roc_RF = metrics.roc_auc_score(p_RF, y_test)\n",
    "print('ROC:', roc_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qual dos dois conjuntos de algoritmos apresentou o melhor resultado?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verifique se combater o desbalanceamento das classes em treino ao ponderar as amostras pelo inverso das frequências de suas classes (utilizando o parâmetro `class_weight='balanced'`) melhora os resultados:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# params = ...\n",
    "# model = ...\n",
    "# grid = ...\n",
    "my_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer( stop_words='english' )),\n",
    "    ('nmf', NMF(n_components=20, init='random', random_state=0)),\n",
    "    ('clf', RandomForestClassifier(min_samples_split=3, class_weight='balanced'))\n",
    "])\n",
    "params = {\n",
    "    'clf__n_estimators': [100,200,300,400,500]\n",
    "}\n",
    "grid = GridSearchCV(my_pipeline, params, n_jobs=1, verbose=2)\n",
    "p_RFB=train_and_report(grid,\n",
    "                 train=(x_train, y_train),\n",
    "                 test=(x_test, y_test),\n",
    "                 classes=target_names)\n",
    "roc_RFB = metrics.roc_auc_score(p_RFB, y_test)\n",
    "print('ROC:', roc_RFB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
